# No Library Neural Network
## About
This neural network that only uses the random library (for weight initialization) and matplotlib (for visuals); it doesn't use any traditional machine learning libraries like Tensorflow, PyTorch, Scikit-Learn or others. The network is based off of HMK Code's step by step tutorial explaining how forward and backward propogation work in updating neural network weights. Please note that this network does not include biases, activation functions, dropout layers or batch normalization layers; it is very basic and only serves as an example of the inner workings of a neural network.

The link to the explanation by HMK Code can be found here: https://hmkcode.com/ai/backpropagation-step-by-step/

Feel free to experiment with the dataset, training process, or network architecture!
